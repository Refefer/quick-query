#!/usr/bin/env python3
from typing import Optional, Dict, List, Any
import argparse
import os
import requests
import select
import sys
import tomllib

def load_toml_file(
    file_path: str
) -> Dict[str, Any]:
    """
    Load and parse a TOML file into a dictionary.

    Args:
        file_path: Path to the TOML file

    Returns:
        Dictionary of parsed TOML data or empty dict if error
    """
    path = os.path.expanduser(file_path)
    if not os.path.exists(path):
        print(f"Error: File not found: {path}")
        return {}

    try:
        with open(path, "rb") as f:
            return tomllib.load(f)

    except tomllib.TOMLDecodeError:
        print(f"Error: Invalid TOML format in {path}")
        return {}


def read_api_conf(
    config_path: str,
    namespace: Optional[str]
) -> Dict[str, Any]:
    """
    Read API configuration from a TOML file for a given namespace.

    Args:
        config_path: Path to the configuration file
        namespace: Section name in the TOML file

    Returns:
        Dict of configuration values
    """
    conf = load_toml_file(config_path)
    ns = namespace or "default"
    return conf.get(ns, {})


def load_toml_prompt(
    file_path: str,
    section_name: Optional[str]
) -> Optional[str]:
    """
    Load a prompt string from a TOML file section.

    Args:
        file_path: Path to the TOML file
        section_name: Name of the section to retrieve

    Returns:
        Prompt string if found, else None
    """
    if not section_name:
        return None

    data = load_toml_file(file_path)
    section = data.get(section_name, {})
    return section.get("prompt")


def build_headers(
    api_key: str
) -> Dict[str, str]:
    """
    Build standard HTTP headers for API requests.

    Args:
        api_key: Authentication key

    Returns:
        Dictionary of HTTP headers
    """
    return {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

def api_request(
    method: str,
    url: str,
    api_key: str,
    json_payload: Optional[Dict[str, Any]] = None
) -> Optional[Dict[str, Any]]:
    """
    Perform a generic API request.

    Args:
        method: HTTP method, "GET" or "POST"
        url: Full request URL
        api_key: Authentication token
        json_payload: JSON data for POST requests

    Returns:
        Parsed JSON response or None on failure
    """
    headers = build_headers(api_key)
    try:
        if method.upper() == "GET":
            response = requests.get(url, headers=headers)
        else:
            response = requests.post(url, headers=headers, json=json_payload)

        response.raise_for_status()
        return response.json()

    except requests.RequestException as e:
        print(f"API Error: {e}")
        return None


def get_model_id(
    api_url: str,
    api_key: str
) -> Optional[str]:
    """
    Retrieve the first available model ID from the API.

    Args:
        api_url: Base API URL
        api_key: Authentication key

    Returns:
        Model ID string or None if not found
    """
    result = api_request("GET", f"{api_url}/models", api_key)
    if not result:
        return None

    data = result.get("data", [])
    if data and isinstance(data, list):
        return data[0].get("id")

    return None


def send_chat_completion(
    api_url: str,
    api_key: str,
    model_id: str,
    messages: List[Dict[str, str]]
) -> Optional[str]:
    """
    Send a chat completion request to the API.

    Args:
        api_url: Base API URL
        api_key: Authentication key
        model_id: Model identifier
        messages: Sequence of chat messages

    Returns:
        Response content or None on failure
    """
    payload = {"model": model_id, "messages": messages}
    result = api_request(
        "POST",
        f"{api_url}/chat/completions",
        api_key,
        json_payload=payload
    )
    if not result:
        return None

    try:
        return result["choices"][0]["message"]["content"]

    except (KeyError, IndexError):
        print("API Error: Unexpected response format")
        return None

def try_read_stdin():
    if select.select([sys.stdin], [], [], 0)[0]:
        return sys.stdin.read()
    else:
        return None

def chat(args, model_id, messages):
    try:
        while True:
            user_input = input("> ").strip()
            if user_input.lower() in ("exit", "quit"):
                break

            messages.append({"role": "user", "content": user_input})
            response = send_chat_completion(
                args.host,
                args.api_key,
                model_id,
                messages
            )

            if response:
                print("AI:", strip_think(response, args.include_think))
                messages.append(
                    {"role": "assistant", "content": response}
                )

    except (KeyboardInterrupt, EOFError):
        print("\nExiting chat.")

def run_prompt(args, user_prompt, model_id, messages):
    prompt = args.prompt
    stdin_prompt = try_read_stdin()
    if stdin_prompt is not None:
        prompt = f"{prompt}\n\n{stdin_prompt}".strip()

    if user_prompt:
        prompt = f"{user_prompt}\n{prompt}"

    messages.append({"role": "user", "content": prompt})
    response = send_chat_completion(
        args.host,
        args.api_key,
        model_id,
        messages
    )
    if response:
        print(strip_think(response, args.include_think))

def main(args) -> None:
    """
    Main execution flow for the script.
    """

    if args.host is None:
        conf = read_api_conf(
            args.conf_file,
            args.server
        )
        args.host = conf.get("host")
        args.api_key = conf.get("api_key")
        args.model = args.model or conf.get("model")

    system_prompt = None
    if args.system_prompt_file and args.system_prompt_name:
        system_prompt = load_toml_prompt(
            args.system_prompt_file,
            args.system_prompt_name
        )
        if not system_prompt:
            return

    user_prompt = None
    if args.user_prompt_file and args.user_prompt_name:
        user_prompt = load_toml_prompt(
            args.user_prompt_file,
            args.user_prompt_name
        )
        if not user_prompt:
            return

    if args.model is None:
        model_id = get_model_id(
            args.host,
            args.api_key
        )
        if not model_id:
            return
    else:
        model_id = args.model

    messages: List[Dict[str, str]] = []
    if system_prompt:
        messages.append(
            {"role": "system", "content": system_prompt}
        )

    if args.chat:
        chat(args, model_id, messages)
    else:
        run_prompt(args, user_prompt, model_id, messages)
        
def strip_think(response, include_think):
    if not include_think:
        # Do not refactor this line of code.  The separation of strings is intentional
        index = response.find('<' + '/think>')
        index = response.find('>', index)
        response = response[index+1:].strip()

    return response

def parse_arguments() -> argparse.Namespace:
    """
    Parse command-line arguments.

    Returns:
        argparse.Namespace of parsed arguments
    """
    parser = argparse.ArgumentParser(description="Query an OpenAI-compatible endpoint")
    parser.add_argument(
        "-p",
        "--prompt",
        required=not "--chat" in sys.argv,
        help="The user's prompt"
    )
    parser.add_argument(
        "--system-prompt-file",
        default=f"{os.environ['HOME']}/.config/quick-query/prompts.toml",
        help="Path to TOML file containing system prompts"
    )
    parser.add_argument(
        "-sp",
        "--system-prompt-name",
        default=None,
        help="Name of the system prompt section in the TOML file"
    )
    parser.add_argument(
        "--user-prompt-file",
        default=f"{os.environ['HOME']}/.config/quick-query/user_prompts.toml",
        help="Path to TOML file containing user prompts"
    )
    parser.add_argument(
        "--user-prompt-name",
        default=None,
        help="Name of the user prompt section in the TOML file"
    )
    parser.add_argument(
        "--conf-file",
        default=f"{os.environ['HOME']}/.config/quick-query/conf.toml",
        help="Path to TOML file containing configuration"
    )
    parser.add_argument(
        "-s",
        dest="server",
        default="default",
        help="Name of the server to connect to in conf.toml"
    )
    parser.add_argument(
        "--host",
        default=None,
        help="API endpoint base URL"
    )
    parser.add_argument(
        "--api-key",
        default=None,
        help="API key for authentication"
    )
    parser.add_argument(
        "--model",
        default=None,
        help="Model identifier"
    )
    parser.add_argument(
        "--include-think",
        action="store_true",
        help="Include <tool_response> blocks. Otherwise strips them out."
    )
    parser.add_argument(
        "-n",
        "--no-think",
        action="store_true",
        help="Appends /nothink to the end of the prompt"
    )
    parser.add_argument(
        "-c",
        "--chat",
        action="store_true",
        help="Enter interactive chat mode"
    )
    return parser.parse_args()


if __name__ == "__main__":
    main(parse_arguments())
